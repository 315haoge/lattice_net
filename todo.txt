
-make prepare cloud return something that doesnt't have a batch of 1, so the first dimensions that is always a 1 doesnt need to appear. The same for the return value of the slicing. It doesnt need to have a 1 as first dimensions
-remove the flags for with_error_checking and with_debug_chekcing



-easypbr should add submodules at a certain release, 
-dataloaders should ahve the same version of pybind as easypbr

-----FOR RSS----

    --comment from the reviewers
        -more explanation on the experiments
        -needs ablations studies
        -the papers has few motivations towards the robotics community
        -the qualittative results are not very useful since they just compare with the ground truth. Maybe we need to also compare with the other works
        -The explanation for downsampling was not very clear for me. Would it be possible to clarify what is meant by the statement: “repeatedly dividing point positions by 2” do you mean the lattice vertex or the actual point cloud data?
            ANSWERED
        -In the downsampling stage, are the vertices of the coarse lattice separated by the vector +/-[-1,….,d,-1….,-1]?
        -It would be great if Figure 4 could be modified to show how coarse lattice vertices on to the left or right of the centre vertex (in figure 4) are embedded onto the finer lattice
        -I have an issue with the lattice vertices in the upsampling stage. It was mentioned in section 3 that the lattice coordinates for a tuple with vertex coordinates that belong to the set of integers. However, in the upsampling section you claim that the separation between the lattice vertices are given by +/-[-0.5,….,-0.5,d/2,-0.5,…..-0.5], which would imply that the vertex coordinates do not belong to the set of integers
            ANSWERED

    -text changes 
        -groupnorm uses the default 32 groups.
            DONE
        -gn-relu-conv became gn-conv-relu
            NO it didnt
        -add the dataset from the bonn activity maps
        -explain why shapenet is not so good sometimes (it is very saturated)
            DONE
        -explain why scannet is not so good ( Minkowsky is run with 5cm and 2cm voxels= calculate what is the average number of points that fall into the influence of a vertex of a voxel and what is the average for our case)
        -make more of an effort to apply it to robotics (autonomous driving or autonomous perception in realtime)
        -hpflow has a nice explanation on why not they slice after each convolution. Maybe we need to say something like that
        -explain CRF ( add abreviation for Conditional Random Field)
            DONE
        - Say in the peformance section: performance and especially memory constumption will likely improve with more specialized cuda kernels. One of the reasons of success of grid like sctructues are libraries like cuddnn which provide extremely  high performance. Since the sparse lattices are not a structure supported in maintream libraries,  the performance is not up to par. We however believe that with more optimization effort this can improve significantly.
        - the matrices D_vg and D_vf are never are not stored explicitly in memory as the PointNEt architecture operates over each point in the point cloud individually.
        - Implementation :
            DeformSlice and the last linear layer are performed in one fused cuda kernel in order to avoid storing high dimensional vectors for each point and then regress the class. 
                DONE
            

    -things to try before we decide on a architecture
        -should dropout be added in the second resnetblock or the first one or maybe even before the two blocks?
            -dropout at the end of second resnetblock seems to get 0.75 on motorbike 
            -dropout at the end of first resnetblock gets 75.2 at epoch at 49, the train loss end up at around 0.41
            -dropout at the beggingin of the first block but after copying the identity  gets 74.9 at epoch at 54, the train loss end up at around 0.41
            -dropout at the beggingin of the first block but before copying the identity 
            -no dropout  WORKS BEST an ti reaches 75.6 on motorbike at epoch 39
            -dropout of 0.2 works best with gngeluconv at reaches 76.0 at epoch 69 after reducing lr twice
        -the final features before slicing is the same as pointnet_start_nr_channels which is usually 32. Even if the semantic kitti one is 64, it is difficult for it to go form 64 features to 20ish class probaiblities. Maybe add a flag for the last finefy to not reduce the number of features from 128 for 64 and just leave them as 64
            -A: done and fixed not the upsampling will output half the nr of channels it has as input
        -should finefy still be gnfinefy or gnfinefygelu
            A: seems to work just as well so we might as well just leave it there
        -semantic kitti probably shouldnt have dropout, nor does shapenet

    -new images
        -show how splatnet works on the semantic kitti by getting the results for that one cloud that we show
        -show how minkowski engine scannet

    -TODO 
        - recheck all related work papers to see if what we say is correct
        - find out which image did we use for the prediction of the cloud in semantic kitti
            We have a few candidates: 
                /home/user/rosu/data/semantic_kitti/test/19/001960.npz
                /home/user/rosu/data/semantic_kitti/test/19/003756.npz
                /home/user/rosu/data/semantic_kitti/test/15/000269.npz
                /home/user/rosu/data/semantic_kitti/test/15/001700.npz
        - the arrows in slice and deform slice kinda go inside the circles, make them touch exactly
            Done
        - add url for related work
            DONE
        -find out how much is the spacial extent of a vertex in latticenet
            DOne
        -fix the architecture because now the deform slice doesnt doa  gn-relu-conv


    RERUNS
        -rerun semantic kitti
        -rerun scannet
    Ablation studies
        slice vs sliceDeform
            -semantic kitti and setting delta weights for slicing to zero
            -semantic kitti and not adding the loss for the detla weights
        Distribute vs splat
            -semantic kitti with pointnet just doing a sum directly on the xyz features (no substraction of the local mean)  and not elevating them
            -semantic kitti with pointnet just doing a sum directly on the xyz features (WITH substraction of the local mean)  and not elevating them
            -semantic kitti with pointnet just doing a sum directly on the xyz features (WITH substraction of the local mean)  and WITH elevating them
            -semantic kitti with pointnet just doing a MAX directly on the xyz features (WITH substraction of the local mean)  and WITH elevating them

            -options: 
                sum or max - maybe this ablation study is not quite neccesary
                -elevate or not - 
                - local mean substraction or not
                This gives us 4 options of elevating or not and substracting local mean or not. Finally a fifth one with doing max instead of a sum
        ShapeNet with different lattice sizes 
            motorbike 
                sigma: 0.020 nr_points_per_simlex: 3, iou: 0.7717
                sigma: 0.025 nr_points_per_simlex: 5, iou
                sigma: 0.05, nr_points_per_simplex: 23.5, iou: #DEFAULT
                sigma: 0.075 nr_points_per_simlex: 51, iou
                sigma: 0.1 nr_points_per_simlex: 84, iou
                sigma: 0.125 nr_points_per_simlex: 115, iou
                sigma: 0.15 nr_points_per_simlex: 156, iou
                sigma: 0.175 nr_points_per_simlex: 204, iou
                sigma: 0.2 nr_points_per_simlex: 238, iou
        Scannet with different sigma sizes
            influence_in_m: 0.02, sigma: X  points_per_simplex: 5 iou:  CANNOT run due to memory
            influence_in_m: 0.05, sigma: X  points_per_simplex: 30 iou:  CANNOT RUN due to memory
            influence_in_m: 0.10, sigma: 0.15  points_per_simplex: 114 iou: No need to run since it's too close to the default sigma of 0.08 (maybe run only if we have time)
            influence_in_m: 0.20, sigma: 0.3  points_per_simplex: 400 iou:  mem: 11.1GB      RUNNING on infcuda2 card 1 
            influence_in_m: 0.40, sigma: 0.6  points_per_simplex: 1430 iou_val: 0.4087  iou_test:   mem: 9.4GB     Running on infcuda2 card 0
            influence_in_m: 0.80, sigma: 1.0  points_per_simplex: 5429 iou: mem: 7.9GB     Running on bigcuda5 card 1
            influence_in_m: 1.60, sigma: 2.4  points_per_simplex: 20798 iou: mem: 7.7GB    Running on bigcuda5 card 3

    -things to implement before starting all the runs   
        -we need to rerun the dockerfile on bg5
            A: DONE
        -we need to rerun the dockerfile on infcuda2

        -need to check that we don't do any inplace operations without calling mark_dirty on the tensors https://pytorch.org/docs/stable/_modules/torch/autograd/function.html  
            A: mostly checked but I a not completely sure
        -shapenet changing of objects automatically and stopping automatically when learning rate decays to a certain amount 
        -cleanup of code so that it's not as verbose
            A: Done
        -maybe check the code again to see it any memory can be saved anywhere
            A: Done
        -abbility to disable the visdom
            A: Done
        -for running experiments we need a flag for experiments with an enum for the type of experiment that will modify the behaviour of pointnet and so on
            -maybe put the flag inside model-params so that the model just receives it
            A: DONE
        -easy scripts to build everything on bg5 or any other machine, things like paths and so on should be easy to modify
        -easy copying of data like semantickitti and scanenet from my local machine towards bg5 or infcuda or whatever else and forth
        -functionality to write only the iou with best iou which we will enable for shapenet because that creates a ton of checkpoints
    
    empty card probably on 
        3,4,7,9,robo5,robo6,robo7,robo1-robo4,cuda12
        The ones with ubuntu 18 for easier docking 
            robo2 - probably used by andre for balloon detection
            robo6 - in use 
            cuda3 -problem with driver mismatch (maybe I can solve it)
            cuda9 -busted driver (maybe I can fix it)

            infcuda2 - 2 cards free
                cannot use it yet because we need the nvidia-container-toolkit https://github.com/NVIDIA/nvidia-docker/issues/1034
            bigcuda 5 - 1 card free if I get peers
            robo7 - FREE with a 12GB RTX2020

    CURRENTLY RUNNING 
        bigcuda5 
            card 1 - semantic kitti with no experiments 


    experiments with deform slice 
        motorbike with vxz movement of 0.2 
            deform slice with a gn-gelu-linear after the gather  
                at iter 600 train loss is 0.229
            deform slice with just a linear layer after the gather 
                at iter 600 train loss is 0.220 so not much of a difference..
            slice_no_deform 
                at iter 600 train loss is 0.230
            doign gathering with deform and with gn-gelu-linear after the gather but the gathering DOESNT multiply by the barycentric coordinates the features it gathers
                at iter 600 train loss is 0.233
            deform slice with a gn-gelu-linear after the gather AND with regularization to of the delta weight to sum up to zero
                0.230
            each vertex predicts the barycentric coordinates individually and there is no gl-gelu-conv
                0.20
            each vertex predicts its barycentric coords but before that the val_dull_dim of each vertex gets substracted from the gamma weighted max over all the vertices in the simplex
                0.199

    maybe start on infcuda on 3 cards: 
        semantic kitti full 
        semantic kitti with slice_no_deform
        scannet full 

    EXPERIMENTS finished:
        semantic kitti on infcuda2:
            pointnet_no_elevate: 0.46376
            pointnet no_local_mean: 0.42592
            splat: 0.373927
            no_experiment: TOD [RUNNING]
            slice_no_deform: TODO [RUNNING]
            slice_no_deform_regularize: TODO
        scanner_on_infcuda2:
            no_experiment: TODO





        


        
        